{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student Name: Vijaykumar Maraviya\n",
    "\n",
    "Student Number: 1006040320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1XDvssQd64Pf"
   },
   "outputs": [],
   "source": [
    "# not required on windows\n",
    "# !apt-get install -y xvfb python-opengl > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F5esgX013vPe"
   },
   "outputs": [],
   "source": [
    "# not required on windows\n",
    "# !pip install gym pyvirtualdisplay > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Qbi2xaFo31Sj"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display as ipythondisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FGqXqJxoAsHG",
    "outputId": "d1e20369-c556-4343-b368-3600f1df8085"
   },
   "outputs": [],
   "source": [
    "# not required on windows\n",
    "# from pyvirtualdisplay import Display\n",
    "# display = Display(visible=0, size=(400, 300))\n",
    "# display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "6L4YayzR4FYj",
    "outputId": "6e3733d6-266b-4c3a-d216-a4d04fc3aedb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations that were run: 26\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v0\")\n",
    "env.reset()\n",
    "prev_screen = env.render(mode='rgb_array')\n",
    "plt.imshow(prev_screen)\n",
    "\n",
    "for i in range(50000):\n",
    "    action = env.action_space.sample()\n",
    "    print(\"step i\",i,\"action=\",action)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    print(\"obs=\",obs,\"reward=\",reward,\"done=\",done,\"info=\",info)\n",
    "    screen = env.render(mode='rgb_array')\n",
    "\n",
    "    plt.imshow(screen)\n",
    "    ipythondisplay.clear_output(wait=True)\n",
    "    ipythondisplay.display(plt.gcf())\n",
    "\n",
    "    if done:\n",
    "        break\n",
    "    \n",
    "ipythondisplay.clear_output(wait=True)\n",
    "env.close()\n",
    "print(\"Iterations that were run:\",i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1:\n",
    "\n",
    "__Can you design a dynamic programming based policy for the agent as in assignment 1? If so, design it and demonstrate that it solves the cart pole problem.__\n",
    "\n",
    "The dynamic programming approach requires the environment model; that is, it requires the information of the state transition probabilities. For the cart-pole environment in the openAI gym, we do not have the model.\n",
    "\n",
    "Additionally, the observation space is continuous. Also, cart velocity and pole velocity at the tip can take any value, at least theoretically. Even if we discretize the state space, we will end up with a large number of states (assuming that our value table contains all the states) that the policy evaluation may take too long to be practically useful.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2:\n",
    "\n",
    "__Can you design a Monte Carlo based policy for the agent? What ingredients do you require? Explain the design flow, and execute it. Show that it works, or indicate why you can't proceed.__\n",
    "\n",
    "We can design a Monte Carlo based policy for an RL agent to balance a cart-pole. However, a few caveats have been mentioned in lecture four and will be covered in the next lecture. Once it is covered, we should be able to use the Monte Carlo approach to create an optimal policy for the cart-pole environment. \n",
    "\n",
    "I have provided arguments for why the approach covered in the lecture so far is not sufficient, as follows:\n",
    "\n",
    "Monte Carlo based approach does not require a model of the environment. Instead, it uses the action-value function Q to create a greedy policy during policy improvement. For a given policy, the Q is estimated during policy evaluation by calculating the average reward over an infinite number of episodes. The episodes are generated by interacting with the environment, real or simulated. The returns observed after the first visit to a state 's' and taking action 'a' over infinite episodes are averaged, which in limit converges to the true value of (s,a) pair. The requirement of experiencing infinite episodes is relaxed by truncating the policy evaluation after one episode. Yet, the algorithm still converges to the optimal policy. However, It is not guaranteed that all the (s,a) pairs will be visited during the episodes, especially with a deterministic policy. To deal with limitation in visiting all (s,a) pairs, two approaches are proposed:\n",
    "\n",
    "1) Exploring starts: the episodes start in a state-action pair (s,a), and that every pair (s,a) has a non-zero probability of being selected as the start.\n",
    "\n",
    "2) Stochastic policy: consider only stochastic policies with a non-zero probability of selecting all actions in each state. \n",
    "\n",
    "If either approach is used, it is guaranteed that all state-action pairs will be visited an infinite number of times in the limit of an infinite number of episodes.\n",
    "\n",
    "The exploring start approach may not be relied upon, specifically when learning from a real environment. The cart-pole problem is an example where the 'exploring starts' approach is not useful because the pendulum starts in an upright position for each episode. Hence, to obtain policy using the Monte Carlo method, we will need to use the stochastic policy approach, which will be covered in the next lecture as mentioned in the 4th lecture. "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "GymRendering.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "MIE1624_env",
   "language": "python",
   "name": "mie1624_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
